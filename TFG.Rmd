title: "Variables"
author: "Fernando González"
date:
output:
pdf\_document: default
word\_document: default
html\_document: default
-----------------------

database

```{r setup_options, message=FALSE, warning=FALSE}
library(readxl)
library(dplyr)
data <- read_excel("C:/Users/Fer/Desktop/TFG_main/Variables.xlsx", sheet = "Full 4") %>%
  mutate_if(is.character, as.factor) %>%
  mutate(origen = as.factor(origen))
```

packages

```{r setup,message=FALSE, warning=FALSE}
library(lintr)
library(syuzhet)
library(quanteda)
library(quanteda.textstats)
library(koRpus)
library(koRpus.lang.es)
library(stringr)
library(tidyr)
library(tm)
library(udpipe)
library(tidytext)
library(wordcloud2)
library(dplyr)
library(SentimentAnalysis)
library(spellcheckr)
library(ggplot2)
library(knitr)
library(RColorBrewer)
library(stargazer)
```

Lee los textos y los guarda en formato tm

```{r}
texts <- Corpus(DirSource("C:/Users/Fer/Desktop/TFG_main/txt"))
texts <- tm_map(texts, content_transformer(as.character))
```

---

Número de oraciones

```{r}
data$nstc <- sapply(texts, function(x) nsentence(x)) 
```

Longitud de texto en palabras

```{r}
data$lengthw <- sapply(texts, function(x) str_count(x, boundary("word")))
```

Signos_exp

```{r}
data$signos_exp <- sapply(texts, function(x) {
  str_count(x, pattern = "[?!]")
})

data$signos_exp <- data$signos_exp / data$nstc
```

Número de párrafos

```{r}
data$pgf <- sapply(texts, function(x) {
  str_count(x, "\n") + 1
})
```

Enumeraciones

```{r}
data$enumeraciones <- sapply(texts, function(x) {
  
  count_numeros <- str_count(x, "(?m)^[0-9]+\\.")
  
  count_guiones <- str_count(x, "(?m)^\\-")
  
  count_numeros + count_guiones
})

data$enum <- data$enumeraciones / data$pgf
```


Pone todo el minúsculas y elimina los signos de puntuación

```{r}
texts <- tm_map(texts, content_transformer(tolower))
texts <- tm_map(texts, removePunctuation)
```

Longitudes de texto en caracteres y longitud media de palabra

```{r}
data$lengthl <- sapply(texts, function(x) nchar(x))
data$wordl <- data$lengthl / data$lengthw
```

Análisis de sentimientos en castellano

```{r}
txt_vec <- iconv(txt_vec, to = "UTF-8")
sent_nrc_all <- get_nrc_sentiment(txt_vec, language = "spanish")
data$sentval <- sent_nrc_all$positive - sent_nrc_all$negative
data$sentm <- data$sentval / rowSums(sent_nrc_all)
```

Patrones de repetición

```{r}
data$patt <- sapply(texts, function(x) {
  nmax <- max(table(unlist(str_extract_all(as.character(x), "\\w+"))))
  return(nmax)
})
data$patt <- data$patt / data$lengthw

data$pattw <- sapply(texts, function(x) {
  freq_table <- table(unlist(str_extract_all(as.character(x), "\\w+")))
  word_with_max_freq <- names(freq_table)[which.max(freq_table)]
  return(word_with_max_freq)
})
data <- data %>% 
  mutate(pattw = as.factor(pattw))
```

Pronombres personales

```{r}
data$pron <- sapply(texts, function(x) str_count(x, pattern = "\\b(yo|tú|vos|usted|él|ella|ello|nosotros|nosotras|vosotros|vosotras|ustedes|ellos|ellas|me|te|lo|la|nos|os|los|las|le|se|les|mí|conmigo|ti|contigo)\\b"))
data$pron <- data$pron / data$lengthw
```

Artículos

```{r}
data$art <- sapply(texts, function(x) str_count(x, pattern = "\\b(el|la|lo|los|las)\\b"))
data$art <- data$art / data$lengthw
```

Variedad léxica

```{r}
data$voc <- sapply(texts, function(x) {
  tokens <- unlist(strsplit(x, " "))
  freq <- table(tokens)
  voc <- names(freq)[freq > 5]
  length(voc)
})
data$voc <- data$voc / data$lengthw
```

Lenguaje informal

```{r}
data$form <- sapply(texts, function(x) str_count(tolower(x),pattern = 
"(un montón de|de todas formas|en fin|en resumen|para resumir|al final|ponerse en contacto|irse|venirse abajo|dar lugar|salir adelante|dar pena|dar igual|dar lo mismo|irse de madre|estar en la parra|meter la pata|largarse|liarse|quedarse|ponerse a|buscar|mirar|investigar|parecerse|entender|probar|esperar a|hablar de|pensar en|pensar sobre|tirar|desechar|llamar|organizar|montar|soportar|aguantar|conformarse|sacar|quitar|llevarse|empezar|mostrar|referirse a|indicar|preguntar|decir|comprar|doler|hacer daño|revisar|comprobar|flipar|flipando|currar|currando|ligar|molaba|molar|molando|fardar|pillar|pasarlo bien|peli|pelis|profe|profes|cole|coles|chaval|chavales|tía|tío|tías|tíos|colega|colegas|curro|curros|movida|movidas|peña|birra|birras|finde|findes|bici|bicis|boli|bolis|cutre|cutres|pastón|pasta|selfi|selfies|bueno|pues|vale|ok|oye|eh|vamos|nada|entonces|en plan|o sea|a ver|ya ves|es que|yo creo que|¿sabes?|básicamente|total|en serio|ni de coña|también|además|gracias|mil gracias|de nada|lo siento|perdona|perdón|súper|genial|guay|horrible|increíble|flipante|feo|bonito|chulo|majete|divertido|aburrido|fácil|difícil|complicado|pesado|barato|peor|gratis|claro|entero)\\b"
))

data$form <- data$form / data$lengthw

```

Lenguaje agresivo

```{r}
palabras <- c(
  "odio", "odiar", "ira", "rabia", "rencor", "venganza", "enemigo", "enemistad", "agresión", "agredir", "violencia", "violento", "violenta", "brutal", "brutalidad", "golpe", "golpear", "hostilidad", "hostil", "ataque", "atacar", "lucha", "pelea", "conflicto", "confrontación", "represalia", "desprecio", "despreciar", "crimen", "criminal", "asesinar", "asesinato", "matar", "muerto", "homicidio", "liquidar", "fusilar", "apuñalar", "apuñalamiento", "disparar", "disparo", "tiroteo", "masacre", "masacrar", "exterminar", "aniquilar", "torturar", "tortura", "castigar", "castigo", "reprimir", "represión", "linchar", "ejecutar", "decapitar", "degollar", "ahorcar", "estrangular", "enfrentar", "derribar", "derrocar", "bombardear", "bombardeo", "bomba", "explosión", "explosivo", "armamento", "armas", "arma", "invadir", "invasión", "expulsar", "expulsión", "vulnerar", "intimidar", "amenazar", "amenaza", "terror", "terrorismo", "terrorista", "horror", "miedo", "pánico", "sangre", "sanguinario", "violador", "ultrajar", "abusar", "abuso", "humillar", "humillación", "maltrato", "maltratar", "dominar", "imponer", "esclavizar", "oprimir", "opresión", "destruir", "destrucción", "colapsar", "silenciar", "gritar", "grito", "apuñalado", "violada", "vengarse", "vengativo", "resistencia", "subversivo", "subversión", "milicia", "militar", "cruel", "crueldad", "agresivo", "agresividad", "injusticia", "odio racial", "racismo", "xenofobia", "golpista", "dictador", "dictadura", "antidemocrático", "autoritarismo", "violencia de género", "machismo", "feminicidio", "escarmentar", "salvajismo", "bestialidad", "barbarie", "repudiar", "reprochar", "escupir", "expulsado", "persecución", "hostigar", "acosar", "acoso", "asediar", "asedio", "bloquear", "bloqueo", "radical", "fanático", "fundamentalista", "odio religioso", "quemar", "incendiar", "linchamiento", "injusto", "vengador", "vengativa", "arma blanca", "arma de fuego", "violador serial", "estrangularon", "ahorcado", "masacraron", "matanza", "golpeó", "herida", "heridas", "tiros", "tiro", "bala", "balas", "ametrallar", "ametralladora", "bomba casera", "bomba nuclear", "bomba atómica", "violencia política", "discriminación", "desprecio social", "odio de clase", "conflicto armado", "intervenir", "intervención", "destrozar", "desfigurar", "caos", "anarquía", "infierno", "batalla", "combate", "rifle", "pistola", "cuchillo", "arma letal", "arma mortal")


contar_palabras <- function(texto) {
  contadores <- sapply(palabras, function(palabra) str_count(texto, pattern = paste0("\\b", palabra, "\\b")))
  return(sum(contadores))
}

aggr <- sapply(texts, contar_palabras)

data$aggr <- aggr
data$aggr <- data$aggr / data$lengthw
```

Conectores

```{r}

conectores <- c(
"sin embargo", "no obstante", "por lo tanto", "por consiguiente", "aun así", "en cambio", "además", "asimismo", "por otra parte", "por otro lado", "de hecho", "es decir", "o sea", "en efecto", "en síntesis", "en resumen", "por ende", "en consecuencia", "finalmente", "para concluir", "para empezar", "en primer lugar", "en segundo lugar", "mientras tanto", "a continuación", "por último", "ante todo", "sobre todo", "sin duda", "ciertamente", "aunque", "a pesar de", "puesto que", "ya que", "porque", "dado que")

patron <- paste0("\\b(", paste(conectores, collapse = "|"), ")\\b")

data$conectores_count <- str_count(
  txt_vec,
  regex(patron, ignore_case = TRUE)
)

data$conectores <- data$conectores_count / data$lengthw

```


Promedio de palabras por oración.

```{r}
data$avw <- data$lengthw / data$nstc
```

Promedio de oraciones por párrafo.

```{r}
data$spgf <- data$nstc / data$pgf
```

Promedio de palabras por párrafo.

```{r}
data$wpgf <- data$lengthw / data$pgf
```

Proporción de oraciones respecto al número total de palabras

```{r}
data$nstcw <- data$nstc / data$lengthw
```

Proporción de párrafos respecto al número total de palabras

```{r}
data$pgfw <- data$pgf / data$lengthw
```

Variabilidad de la frecuencia

```{r}
data$freqv <- sapply(texts, function(x) {
  tokens <- unlist(strsplit(x, " "))
  freq <- table(tokens)
  sd(freq)
})
```

Relación entre palabras únicas y el total

```{r}
data$typew <- sapply(texts, function(x) {
  tokens <- unlist(strsplit(x, " "))
  freq <- table(tokens)
  voc <- names(freq)[freq > 5]
  length(voc) / str_count(x, boundary("word"))
})
```

Suma de palabras repetidas

```{r}
data$sumrep <- sapply(texts, function(x) {
  tokens <- unlist(strsplit(x, " "))
  freq <- table(tokens)
  sum(freq[freq > 1])
})
data$sumrep <- data$sumrep / data$lengthw
```

Que

```{r}
data$que <- sapply(texts, function(x) str_count(x, pattern = "\\b(que)\\b"))
data$que <- data$que / data$lengthw
```

La

```{r}
data$la <- sapply(texts, function(x) str_count(x, pattern = "\\b(la)\\b"))
data$la <- data$la / data$lengthw
```

FleschSzigriszt

```{r}
data$silabas <- data$lengthw * 1.69

data$flesch <- 206.835 - 62.3 * (data$silabas / data$lengthw) - (data$lengthw / data$nstc)
```

POS

```{r}
ud_model <- udpipe_download_model(language = "spanish")

ud_model <- udpipe_load_model(ud_model$file_model)

anno <- udpipe_annotate(ud_model, x = txt_vec, doc_id = seq_along(txt_vec))
anno_df <- as.data.frame(anno)

total_tokens <- anno_df %>%
  group_by(doc_id) %>%
  summarise(total = n())

upos_counts <- anno_df %>%
  filter(upos %in% c("NOUN", "VERB", "ADJ", "ADV")) %>%
  group_by(doc_id, upos) %>%
  summarise(count = n(), .groups = "drop") %>%
  pivot_wider(names_from = upos, values_from = count, values_fill = 0)

# Aquí pillo las proporciones
upos_props <- left_join(upos_counts, total_tokens, by = "doc_id") %>%
  mutate(
    NOUN_prop = NOUN / total,
    VERB_prop = VERB / total,
    ADJ_prop  = ADJ  / total,
    ADV_prop  = ADV  / total
  ) %>%
  select(doc_id, NOUN_prop, VERB_prop, ADJ_prop, ADV_prop)

data$doc_id <- seq_len(nrow(data))
upos_props$doc_id <- as.integer(upos_props$doc_id)

data <- left_join(data, upos_props, by = "doc_id")

data <- select(data, -doc_id)

boxplot(data$NOUN_prop ~ data$origen, main = "Sustantivos (%)")
boxplot(data$VERB_prop ~ data$origen, main = "Verbos (%)")
boxplot(data$ADJ_prop ~ data$origen, main = "Adjetivos (%)")
boxplot(data$ADV_prop ~ data$origen, main = "Adverbios (%)")

# Test
t.test(data$NOUN_prop ~ data$origen)
t.test(data$VERB_prop ~ data$origen)
t.test(data$ADJ_prop ~ data$origen)
t.test(data$ADV_prop ~ data$origen)
```

**EDA**

**Categorical Variables**

*Origen*

```{r}
table_origen <- table(data$origen)
prop_origen <- prop.table(table_origen)
prop_origen
```

```{r}
ggplot(data, aes(x=origen)) + 
  geom_bar(fill= c("#4DAF4A", "#00CED1")) + 
  xlab("origen") + 
  ylab("Frecuencia") + 
  ggtitle("Textos: Humano (0) o Inteligencia Artificial (1)")
```

*Categoría*

```{r}
table_categoria <- table(data$categoria)
prop_categoria <- prop.table(table_categoria)
prop_categoria
```

```{r}
ggplot(data, aes(x=categoria, fill=categoria)) + 
  geom_bar() + 
  xlab("Clase") + 
  ylab("Número") + 
  ggtitle("Clases de textos") +
  scale_fill_brewer(palette = "Set2") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1), legend.position = "none")
```

*Año*

```{r}
table_anio <- table(data$anio)
prop_anio <- prop.table(table_anio)
prop_anio
```

```{r}
ggplot(data, aes(x=anio)) +
geom_bar(fill="#7570B3") +
xlab("Año") +
ylab("Número") +
ggtitle("Años en los que se crearon los textos humanos")
```

*Pattw*

```{r}
table_pattw <- table(data$pattw)
prop_pattw <- prop.table(table_pattw)
prop_pattw
```

```{r}
data$pattw <- factor(data$pattw, levels = names(sort(table(data$pattw), decreasing = TRUE)))

ggplot(data, aes(x=pattw)) + 
  geom_bar(fill="#7570B3") + 
  xlab("Palabra") + 
  ylab("Número de textos") + 
  ggtitle("Palabras utilizadas con más frecuencia en los textos") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

**Numeric variables**

```{r}
nombres <- c("lengthl", "lengthw", "pgf", "nstc", "wordl", "sentm", "sentval", "patt", "pron", "art", "voc", "form", "aggr", "avw", "spgf", "wpgf", "nstcw", "pgfw", "freqv", "typew", "sumrep")

par(mfrow = c(5, 5), mar = c(2, 2, 1, 1), oma = c(0, 0, 2, 0), las = 1, cex.axis = 0.7, cex.main = 0.8, cex.lab = 0.7, ps = 8)

par(pty = "s")

for (i in 1:20) {
  boxplot(data[[nombres[i]]], col = "lightblue", main = nombres[i], ylab = "Valor")
}

mtext("Boxplots", outer = TRUE, cex = 1.5)
```

*Lengthl*

```{r}
summary(data$lengthl)
```

```{r}
sd(data$lengthl)
```

```{r}
boxplot(data$lengthl)
# dlengthl <- density(data$lengthl)
```

*Lengthw*

```{r}
summary(data$lengthw)
```

```{r}
sd(data$lengthw)
```

```{r}
boxplot(data$lengthw)
# dlengthw <- density(data$lengthw)
```

*Pgf*

```{r}
summary(data$pgf)
```

```{r}
sd(data$pgf)
```

```{r}
boxplot(data$pgf)
# dpgf <- density(data$pgf)
```

*Nstc*

```{r}
summary(data$nstc)
```

```{r}
sd(data$nstc)
```

```{r}
boxplot(data$nstc)
# dnstc <- density(data$nstc)
```

*Wordl*

```{r}
summary(data$wordl)
```

```{r}
sd(data$wordl)
```

```{r}
boxplot(data$wordl)
# dwordl <- density(data$wordl)
```

*Enum*

```{r}
summary(data$enum)
```

```{r}
sd(data$enum)
```

```{r}
boxplot(data$enum)
```

*sentm*

```{r}
summary(data$sentm)
```

```{r}
sd(data$sentm)
```

```{r}
boxplot(data$sentm)
```

*Sentval*

```{r}
summary(data$sentval)
```

```{r}
sd(data$sentval)
```

```{r}
boxplot(data$sentval)
```

*Patt*

```{r}
summary(data$patt)
```

```{r}
sd(data$patt)
```

```{r}
boxplot(data$patt)
# dpatt <- density(data$patt)
```

*Pron*

```{r}
summary(data$pron)
```

```{r}
sd(data$pron)
```

```{r}
boxplot(data$pron)
```

*Art*

```{r}
summary(data$art)
```

```{r}
sd(data$art)
```

```{r}
boxplot(data$art)
```

*Voc*

```{r}
summary(data$voc)
```

```{r}
sd(data$voc)
```

```{r}
boxplot(data$voc)
```

*Form*

```{r}
summary(data$form)
```

```{r}
sd(data$form)
```

```{r}
boxplot(data$form)
```

*Aggr*

```{r}
summary(data$aggr)
```

```{r}
sd(data$aggr)
```

```{r}
boxplot(data$aggr)
```

*Conectores*

```{r}
summary(data$conectores)
```

```{r}
sd(data$conectores)
```

```{r}
boxplot(data$conectores)
```

*Avw*

```{r}
summary(data$avw)
```

```{r}
sd(data$avw)
```

```{r}
boxplot(data$avw)
```

*Spgf*

```{r}
summary(data$spgf)
```

```{r}
sd(data$spgf)
```

```{r}
boxplot(data$spgf)
```

*Wpgf*

```{r}
summary(data$wpgf)
```

```{r}
sd(data$wpgf)
```

```{r}
boxplot(data$wpgf)
```

*Nstcw*

```{r}
summary(data$nstcw)
```

```{r}
sd(data$nstcw)
```

```{r}
boxplot(data$nstcw)
```

*Pgfw*

```{r}
summary(data$pgfw)
```

```{r}
sd(data$pgfw)
```

```{r}
boxplot(data$pgfw)
```

*Freqv*

```{r}
summary(data$freqv)
```

```{r}
sd(data$freqv)
```

```{r}
boxplot(data$freqv)
```

*Typew*

```{r}
summary(data$typew)
```

```{r}
sd(data$typew)
```

```{r}
boxplot(data$typew)
```

*Sumrep*

```{r}
summary(data$sumrep)
```

```{r}
sd(data$sumrep)
```

```{r}
boxplot(data$sumrep)
```

*signos_exp*

```{r}
summary(data$signos_exp)
```

```{r}
sd(data$signos_exp)
```

```{r}
boxplot(data$signos_exp)
```

*que*

```{r}
summary(data$que)
```

```{r}
sd(data$que)
```

```{r}
boxplot(data$que)
```

*La*

```{r}
summary(data$la)
```

```{r}
sd(data$la)
```

```{r}
boxplot(data$la)
```

*FleschSzigriszt*

```{r}
summary(data$flesch)
```

```{r}
sd(data$flesch)
```

```{r}
boxplot(data$flesch)
```

**origen and Categorical Variables**

*origen & anio*

```{r}
out_anio <- table(data$anio, data$origen)
prop.table(out_anio)
anio_chi <- chisq.test(out_anio, correct = FALSE, simulate.p.value = TRUE)
print(anio_chi)
```

```{r}
ggplot(data, aes(x = as.factor(origen), fill = as.factor(anio))) + 
  geom_bar(position = "stack")

ggplot(data, aes(x = as.factor(origen), fill = as.factor(anio))) + 
  geom_bar(position = "dodge")
```

*origen & Pattw*

```{r}
out_pattw <- table(data$pattw, data$origen)
prop.table(out_pattw)
pattw_chi <- chisq.test(out_pattw, correct = FALSE, simulate.p.value = TRUE)
print(pattw_chi)
```

```{r}
library(dplyr)
library(forcats) 

top_words <- data %>% 
  count(pattw) %>% 
  arrange(desc(n)) %>% 
  slice_head(n = 15) %>% 
  pull(pattw)

# filter the original data to include only the top 15 words
data_filtered <- data %>% 
  filter(pattw %in% top_words)

ggplot(data_filtered, aes(x = pattw, fill = factor(origen, levels = c(1, 0)), width = ifelse(pattw %in% c("word_AI", "word_human"), 1, 0.8))) +
  geom_bar(position = "dodge") +
  facet_wrap(~ pattw, ncol = 5, scales = "free_x") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = "Análisis bivariado de las palabras más frecuentes", y = "Frecuencia", fill = "Origen") +
  scale_fill_manual(values = c("#F8766D", "#00BFC4"), labels = c("IA", "Humano")) +
  guides(fill = guide_legend(reverse = TRUE)) 
```

**origen and Numeric Variables**

*origen & Lengthl*

```{r}
boxplot(data$lengthl ~ data$origen, 
        main = "Boxplot Lengthl",
        xlab = "origen", ylab = "lengthl")

ttest1 <- t.test(data$lengthl ~ data$origen)
print(ttest1)
```

*origen & Lengthw*

```{r}
boxplot(data$lengthw  ~ data$origen, 
        main = "Boxplot Lengthw",
        xlab = "origen", ylab = "lengthw")

ttest2 <- t.test(data$lengthw ~ data$origen)
print(ttest2)
```

*origen & pgf*

```{r}
boxplot(data$pgf ~ data$origen, 
        main = "Boxplot Pgf",
        xlab = "origen", ylab = "pgf")

ttest3 <- t.test(data$pgf ~ data$origen)
print(ttest3)
```

*origen & Nstc*

```{r}
boxplot(data$nstc ~ data$origen, 
        main = "Boxplot Nstc",
        xlab = "origen", ylab = "nstc")

ttest4 <- t.test(data$nstc ~ data$origen)
print(ttest4)
```

*origen & Wordl*

```{r}
boxplot(data$wordl ~ data$origen, 
        main = "Boxplot Wordl",
        xlab = "origen", ylab = "wordl")

ttest5 <- t.test(data$wordl ~ data$origen)
print(ttest5)
```

*origen & Enum*

```{r}
boxplot(data$enum ~ data$origen, 
        main = "Boxplot Enum",
        xlab = "origen", ylab = "Enum")

ttest6 <- t.test(data$enum ~ data$origen)
print(ttest6)
```

*Origen & sentm*

```{r}
boxplot(data$sentm ~ data$origen, 
        main = "Boxplot sentm",
        xlab = "origen", ylab = "sentm")

ttest7 <- t.test(data$sentm ~ data$origen)
print(ttest7)
```

*Origen & Sent_sd*

```{r}
boxplot(data$sentval ~ data$origen, 
        main = "Boxplot Sent_sd",
        xlab = "origen", ylab = "sent_sd")

ttest8 <- t.test(data$sentval ~ data$origen)
print(ttest8)
```

*origen & Patt*

```{r}
boxplot(data$patt ~ data$origen, 
        main = "Boxplot Patt",
        xlab = "origen", ylab = "patt")

ttest9 <- t.test(data$patt ~ data$origen)
print(ttest9)
```

*origen & Pron*

```{r}
boxplot(data$pron ~ data$origen, 
        main = "Boxplot Pron",
        xlab = "origen", ylab = "pron")

ttest10 <- t.test(data$pron ~ data$origen)
print(ttest10)
```

*origen & Art*

```{r}
boxplot(data$art ~ data$origen, 
        main = "Boxplot Art",
        xlab = "origen", ylab = "art")

ttest11 <- t.test(data$art ~ data$origen)
print(ttest11)
```

*origen & Voc*

```{r}
boxplot(data$voc ~ data$origen, 
        main = "Boxplot Voc",
        xlab = "origen", ylab = "voc")

ttest12 <- t.test(data$voc ~ data$origen)
print(ttest12)
```

*origen & Form*

```{r}
boxplot(data$form ~ data$origen, 
        main = "Boxplot Form",
        xlab = "origen", ylab = "form")

ttest13 <- t.test(data$form ~ data$origen)
print(ttest13)
```

*origen & Aggr*

```{r}
boxplot(data$aggr ~ data$origen, 
        main = "Boxplot Aggr",
        xlab = "origen", ylab = "aggr")

ttest14 <- t.test(data$aggr ~ data$origen)
print(ttest14)
```

*origen & Conectores*

```{r}
boxplot(data$conectores ~ data$origen, 
        main = "Boxplot Conectores",
        xlab = "origen", ylab = "conectores")

ttest15 <- t.test(data$conectores ~ data$origen)
print(ttest15)
```

*origen & Avw*

```{r}
boxplot(data$avw ~ data$origen, 
        main = "Boxplot Avw",
        xlab = "origen", ylab = "avw")

ttest16 <- t.test(data$avw ~ data$origen)
print(ttest16)
```

*origen & Spgf*

```{r}
boxplot(data$spgf ~ data$origen, 
        main = "Boxplot Spgf",
        xlab = "origen", ylab = "spgf")

ttest17 <- t.test(data$spgf ~ data$origen)
print(ttest17)
```

*origen & Wpgf*

```{r}
boxplot(data$wpgf ~ data$origen, 
        main = "Boxplot Wpgf",
        xlab = "origen", ylab = "wpgf")

ttest18 <- t.test(data$wpgf ~ data$origen)
print(ttest18)
```

*origen & Nstcw*

```{r}
boxplot(data$nstcw ~ data$origen, 
        main = "Boxplot Nstcw",
        xlab = "origen", ylab = "nstcw")

ttest19 <- t.test(data$nstcw ~ data$origen)
print(ttest19)
```

*origen & Pgfw*

```{r}
boxplot(data$pgfw ~ data$origen, 
        main = "Boxplot Pgfw",
        xlab = "origen", ylab = "pgfw")

ttest20 <- t.test(data$pgfw ~ data$origen)
print(ttest20)
```

*origen & Freqv*

```{r}
boxplot(data$freqv ~ data$origen, 
        main = "Boxplot Freqv",
        xlab = "origen", ylab = "freqv")

ttest21 <- t.test(data$freqv ~ data$origen)
print(ttest21)
```

*origen & Typew*

```{r}
boxplot(data$typew ~ data$origen, 
        main = "Boxplot Typew",
        xlab = "origen", ylab = "typew")

ttest22 <- t.test(data$typew ~ data$origen)
print(ttest22)
```

*origen & Sumrep*

```{r}
boxplot(data$sumrep ~ data$origen, 
        main = "Boxplot Sumrep",
        xlab = "origen", ylab = "sumrep")

ttest23 <- t.test(data$sumrep ~ data$origen)
print(ttest23)
```

*origen & Signos_exp*

```{r}
boxplot(data$signos_exp ~ data$origen, 
        main = "Boxplot de diálogo/expresividad",
        xlab = "origen",
        ylab = "dialogo",
        col = c("skyblue", "lightgreen"))

ttest24 <- t.test(data$signos_exp ~ data$origen)
print(ttest24)
```

*origen & Que*

```{r}
boxplot(data$que ~ data$origen, 
        main = "Boxplot que",
        xlab = "origen", ylab = "que")

ttest25 <- t.test(data$que ~ data$origen)
print(ttest25)
```

*origen & La*

```{r}
boxplot(data$la ~ data$origen, 
        main = "Boxplot La",
        xlab = "origen", ylab = "La")

ttest26 <- t.test(data$la ~ data$origen)
print(ttest26)
```

*origen & FleschSzigriszt*

```{r}
boxplot(data$flesch ~ data$origen, 
        main = "Boxplot flesch",
        xlab = "origen", ylab = "Índice")

ttest27 <- t.test(data$flesch ~ data$origen)
print(ttest27)
```

que

```{r}
data$que <- sapply(texts, function(x) str_count(x, pattern = "\\b(que)\\b"))
data$que <- data$que / data$lengthw
```

la

```{r}
data$la <- sapply(texts, function(x) str_count(x, pattern = "\\b(la)\\b"))
data$la <- data$la / data$lengthw
```

```{r}
# install.packages(c("rpart", "rpart.plot"))
```

```{r}
library(tidyverse)
library(DescTools)
library(rpart)
library(rpart.plot)
library(caret)
```

```{r}
library(dplyr)
data <- select(data, -c(id, fuente, anio, lengthl, lengthw, pgf, nstc, enumeraciones, silabas, sentval))
```

# Árbol de decisión

```{r}
set.seed(1649)
suppressMessages(library(caret))

data.tree = rpart(origen ~ ., 
                  data=data, 
                  method="class")

data.tree
```

```{r}
library(rpart.plot)
rpart.plot(data.tree, uniform=TRUE,
           main="Classification Tree")
```

```{r}
print(data.tree)         # Resumen general
summary(data.tree)       # Más detalles del modelo
print(data.tree$bestTune) # Muestra los mejores parámetros
```


```{r}
set.seed(1649)

# Define una cuadrícula de búsqueda para cp
tuneGrid <- expand.grid(cp = seq(0.001, 0.1, length.out = 100))

# Configuración de validación cruzada; en este ejemplo se usan 10 folds
ctrl <- trainControl(method = "cv", number = 10)

data.tree1 <- train(origen ~ ., 
                   data = data, 
                   method = "rpart", 
                   trControl = ctrl, 
                   tuneGrid = tuneGrid)

# Muestra el cp óptimo encontrado y el accuracy asociado
print(data.tree1)
rpart.plot(data.tree1$finalModel, uniform = TRUE, main = "Árbol de Decisión Optimizado")
```

```{r}
predictions <- predict(data.tree1, newdata = data)

cm <- confusionMatrix(predictions, data$origen)
kappa <- cm$overall['Kappa']
print(kappa)


library(ROCR)
library(pROC)

pred1 <- predict(data.tree1, newdata = data, type = "prob")[, 2]

roc_obj1 <- roc(data$origen, pred1)

auc1 <- auc(roc_obj1)
print(auc1)
```

```{r}
cm1 <- confusionMatrix(data.tree1)
cm1
```

```{r}
34.4 / (34.4 + 5) # ppv
34.4 / (34.4 + 15.6) # recall
```

cp = 0.04

```{r}
set.seed(1649)
suppressMessages(library(caret))
data.tree2 <- train(origen ~ ., 
                   data = data, 
                   method = "rpart", 
                   trControl = trainControl(method = "cv"), 
                   tuneGrid = data.frame(cp = 0.04))

rpart.plot(data.tree2$finalModel, uniform=TRUE,
           main="Classification Tree with cp = 0.04")
```

# Bosque Aleatorio

```{r}
set.seed(1649)
library(caret)
library(randomForest)

ctrl <- trainControl(method = "repeatedcv", 
                     number = 5, 
                     repeats = 10)

rf_model <- train(origen ~ ., 
                  data = data, 
                  method = "rf", 
                  trControl = ctrl, 
                  tuneLength = 5)

print(rf_model)
class(rf_model$finalModel)
varImp(rf_model)
```

```{r}
ImpData <- varImp(rf_model)$importance
```

```{r}
ImpData <- as.data.frame(varImp(rf_model)$importance)
ImpData$Var.Names <- rownames(ImpData)
```

```{r}
threshold <- 0.2 
relevant_vars <- ImpData[ImpData$Overall > threshold, , drop = FALSE]

relevant_vars <- relevant_vars[order(relevant_vars$Overall, decreasing = TRUE), ]

num_vars_to_show <- 25 
relevant_vars <- head(relevant_vars, num_vars_to_show)

ggplot(relevant_vars, aes(x = Var.Names, y = Overall)) +
  geom_segment(aes(x = Var.Names, xend = Var.Names, y = 0, yend = Overall), color = "skyblue") +
  geom_point(aes(size = Overall), color = "blue", alpha = 0.6) +
  theme_light() +
  coord_flip() +
  theme(
    legend.position = "bottom",
    panel.grid.major.y = element_blank(),
    panel.border = element_blank(),
    axis.ticks.y = element_blank()
  )
```

```{r}
predictions <- predict(rf_model, newdata = data)
probabilities <- predict(rf_model, newdata = data, type = "prob")

library(pROC)
roc_obj2 <- roc(data$origen, probabilities[, "1"])
auc <- auc(roc_obj2)

print(auc)
```

```{r}
confusionMatrix(rf_model)
```

```{r}
38.4 / (38.4 + 5.6) # ppv
38.4 / (38.4 + 11.6) # recall
```

# Logistic Model

```{r}
data$sumrep_100 <- 100 * data$sumrep
data$que_100 = 100 * data$que
```

```{r}
library(caret)
model = train(
  form = origen ~ sumrep_100 + wpgf + que_100 + categoria + freqv,
  data = data,
  trControl = trainControl(method = "cv", number = 5),
  method = "glm",
  family = "binomial"
)

summary(model)
```

```{r}
predicts <- predict(model, newdata = data)
cm <- confusionMatrix(predicts, data$origen)
cm$overall["Kappa"]
```

```{r}
probs <- predict(model, newdata = data, type = "prob")[, 2]
roc(data$origen, probs)$auc
```

```{r}
confusionMatrix(model)
```

```{r}
43.1 / (43.1 + 6.9) # ppv
43.1 / (43.1 + 6.9) # recall
```

```{r}
set.seed(1649)

probabilities <- predict(model, newdata = data, type = "prob")

roc <- roc(data$origen, probabilities[, "1"])

plot(roc, main = "Logistic model ROC curve")
```

# Support Vector Machines

Lineal SVM:

```{r}
set.seed(1649)
library(e1071)
M=4
accuracy.vector2 = 0:M
num.supp.vect2 = 0:M

cq=seq(1,100, M+1)

for(i in 1:length(cq)){
svm.model = svm(origen ~ ., data = data, kernel = "linear", cost = cq[i], scale = T, probability = T)

svm.pred <- predict(svm.model, newdata = data[,-1])

t2<-table(svm.pred, data$origen)
n<-nrow(data)
accuracy.vector2[i] <- (sum(diag(t2))/n)
num.supp.vect2[i] = svm.model$tot.nSV

cat(i, "accuracy:", accuracy.vector2[i], "number of support vectors = ", num.supp.vect2[i], "\n" )
}
```

```{r}
best_c_linear = cq[which.max(accuracy.vector2/ num.supp.vect2)]
best_accuracy_linear = accuracy.vector2[which.max(accuracy.vector2/ num.supp.vect2)]
best_accuracy_linear
num.supp.vect2[which.max(accuracy.vector2/ num.supp.vect2)]
best_c_linear
```

```{r}
p <- 0.7          
n <- dim(data)[1]          
set.seed(1649)
train.sel <- sample(c(FALSE,TRUE),n,rep=TRUE,prob=c(1-p,p))
train <- data[train.sel,]
test <- data[!train.sel,]
```

```{r}
set.seed(1649)
svm_2 = svm(origen ~ ., data = train, kernel = "linear", cost = 76, scale = TRUE, probability=TRUE)

confusionMatrix(predict(svm_2, newdata = test[,-1]),test$origen) 
```

```{r}
18/(18+4) # ppv
18/(18+2) # recall
```

```{r}
set.seed(1649)
library(pROC)
PRED <- predict(svm_2, newdata = test[,-1],probability = TRUE)
# head(attr(PRED, "probabilities"))
pred <- attr(PRED, "probabilities")[,2]
roc2 <- roc(test$origen,pred)
```

```{r}
plot(roc2, main = "linear SVM ROC curve")
```

Radial SVM:

```{r}
M=4
accuracy.vector3 = matrix(0, M+1, M+1)
num.supp.vect3 = matrix(0, M+1, M+1)

for(i in 0:M){
  for(j in 0:M){
svm.model2 = svm(origen ~ ., data = data, kernel = "radial", cost = 10^i, gamma=10^(-j))

svm.pred2 <- predict(svm.model2, newdata = data[,-1])

t3<-table(svm.pred2, data$origen)
n2<-nrow(data)
accuracy.vector3[i+1, j+1] <- (sum(diag(t3))/n)
num.supp.vect3[i+1, j+1] = svm.model$tot.nSV

cat(i, "-", j, "accuracy:", accuracy.vector3[i+1, j+1], "number of support vectors = ", num.supp.vect3[i+1, j+1], "\n" )
  }
}
```

```{r}
df3 = as.data.frame(accuracy.vector3)
rownames(df3)=10^(0:M)
colnames(df3)=10^-(0:M)
df3
```

```{r}
which(as.matrix(df3)==max(df3), arr.ind=T)
best_accuracy_radial = max(df3)
```

```{r}
p <- 0.7              
n <- dim(data)[1]           
set.seed(1649)
train.sel <- sample(c(FALSE,TRUE),n,rep=TRUE,prob=c(1-p,p))
train <- data[train.sel,]
test <- data[!train.sel,]
```

```{r}
set.seed(1649)
svm_3 = svm(origen ~ ., data = train, kernel = "radial", cost = 1, gamma = 1, scale = TRUE, probability=TRUE)

confusionMatrix(predict(svm_3, newdata = test[,-1]),test$origen) 
```

```{r}
20/(20+24) # ppv
20/(20+0) # recall
```

```{r}
set.seed(1649)
library(pROC)
PRED2 <- predict(svm_3, newdata = test[,-1],probability = TRUE)
# head(attr(PRED, "probabilities"))
pred2 <- attr(PRED2, "probabilities")[,2]
roc3 <- roc(test$origen,pred2)
```

```{r}
plot(roc3, main = "radial SVM ROC curve")
```

```{r}
plot(roc2, main = "Linear SVM vs Radial SVM ROC curves")
plot(roc3, add = TRUE, col = "steelblue")
legend("bottomright", legend = c("Linear SVM", "Radial SVM"), col = c("black", "steelblue"), lty = 1)
```
```{r}
library(ggplot2)
library(plotly)
p <- ggplot(data, aes(x = ADJ_prop, fill = factor(origen))) +
  geom_density(alpha = 0.5) +
  labs(title = "Distribución de adjetivos", fill = "Origen")

ggplotly(p)
```